{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nest_asyncio\n",
    "\n",
    "nest_asyncio.apply()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Literal\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "from IPython.display import Image, display\n",
    "from langchain_core.messages import HumanMessage, SystemMessage, ToolMessage\n",
    "from langchain_core.tools import tool\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "from langgraph.graph import END, START, MessagesState, StateGraph\n",
    "from langgraph.types import Command, interrupt\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "model = ChatOpenAI(model=\"gpt-4.1-mini\", temperature=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# THIS IS DANGEROUS, DO NOT USE IN PRODUCTION\n",
    "@tool\n",
    "def run_python_code(code: str) -> str:\n",
    "    \"\"\"Run arbitrary Python code including imports, assignments, and statements. Do not use any external libraries. Save your results as a variable.\n",
    "\n",
    "    Args:\n",
    "        code: Python code to run\n",
    "    \"\"\"\n",
    "    import sys\n",
    "    from io import StringIO\n",
    "\n",
    "    old_stdout = sys.stdout\n",
    "    sys.stdout = captured_output = StringIO()\n",
    "\n",
    "    namespace = {}\n",
    "\n",
    "    try:\n",
    "        exec(code, namespace)\n",
    "\n",
    "        output = captured_output.getvalue()\n",
    "\n",
    "        if not output.strip():\n",
    "            user_vars = {\n",
    "                k: v\n",
    "                for k, v in namespace.items()\n",
    "                if not k.startswith(\"__\") and k not in [\"StringIO\", \"sys\"]\n",
    "            }\n",
    "            if user_vars:\n",
    "                if len(user_vars) == 1:\n",
    "                    output = str(list(user_vars.values())[0])\n",
    "                else:\n",
    "                    output = str(user_vars)\n",
    "\n",
    "        return output.strip() if output.strip() else \"Code executed successfully\"\n",
    "\n",
    "    except Exception as e:\n",
    "        return f\"Error: {str(e)}\"\n",
    "    finally:\n",
    "        sys.stdout = old_stdout\n",
    "\n",
    "\n",
    "# THIS IS DANGEROUS, DO NOT USE IN PRODUCTION\n",
    "\n",
    "\n",
    "def human_review_node(state) -> Command[Literal[\"call_llm\", \"run_tool\"]]:\n",
    "    last_message = state[\"messages\"][-1]\n",
    "    tool_call = last_message.tool_calls[-1]\n",
    "\n",
    "    human_review = interrupt(\n",
    "        {\n",
    "            \"question\": \"Do you want to continue?\",\n",
    "            # Surface tool calls for review\n",
    "            \"tool_call\": tool_call,\n",
    "        }\n",
    "    )\n",
    "\n",
    "    review_action = human_review[\"action\"]\n",
    "    review_data = human_review.get(\"data\")\n",
    "\n",
    "    # if approved, call the tool\n",
    "    if review_action == \"continue\":\n",
    "        return Command(goto=\"run_tool\")\n",
    "    # provide feedback to LLM\n",
    "    elif review_action == \"feedback\":\n",
    "        tool_message = {\n",
    "            \"role\": \"tool\",\n",
    "            \"content\": review_data,\n",
    "            \"name\": tool_call[\"name\"],\n",
    "            \"tool_call_id\": tool_call[\"id\"],\n",
    "        }\n",
    "        return Command(goto=\"call_llm\", update={\"messages\": [tool_message]})\n",
    "\n",
    "\n",
    "tools = [run_python_code]\n",
    "tools_by_name = {tool.name: tool for tool in tools}\n",
    "model_with_tools = model.bind_tools(tools)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class State(MessagesState):\n",
    "    llm_output: str\n",
    "\n",
    "\n",
    "def call_llm(state: State):\n",
    "    messages = [\n",
    "        SystemMessage(content=\"You are a helpful assistant that can run python code.\"),\n",
    "    ] + state[\"messages\"]\n",
    "    response = model_with_tools.invoke(messages)\n",
    "    return {\"messages\": [response]}\n",
    "\n",
    "\n",
    "def tool_node(state: State):\n",
    "    result = []\n",
    "    for tool_call in state[\"messages\"][-1].tool_calls:\n",
    "        tool = tools_by_name[tool_call[\"name\"]]\n",
    "        observation = tool.invoke(tool_call[\"args\"])\n",
    "        result.append(ToolMessage(content=observation, tool_call_id=tool_call[\"id\"]))\n",
    "    return {\"messages\": result}\n",
    "\n",
    "\n",
    "def route_after_llm(state: State) -> Literal[END, \"human_review_node\"]:\n",
    "    if len(state[\"messages\"][-1].tool_calls) == 0:\n",
    "        return END\n",
    "    else:\n",
    "        return \"human_review_node\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "memory = MemorySaver()\n",
    "\n",
    "builder = StateGraph(MessagesState)\n",
    "builder.add_node(\"call_llm\", call_llm)\n",
    "builder.add_node(\"run_tool\", tool_node)\n",
    "builder.add_node(\"human_review_node\", human_review_node)\n",
    "builder.add_edge(START, \"call_llm\")\n",
    "builder.add_conditional_edges(\"call_llm\", route_after_llm)\n",
    "builder.add_edge(\"run_tool\", \"call_llm\")\n",
    "\n",
    "agent = builder.compile(checkpointer=memory)\n",
    "\n",
    "display(Image(agent.get_graph(xray=True).draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pprint import pprint\n",
    "\n",
    "memory.delete_thread(\"1\")\n",
    "\n",
    "config = {\"configurable\": {\"thread_id\": \"1\"}}\n",
    "output = agent.invoke(\n",
    "    {\"messages\": [HumanMessage(content=\"Give me 20 random number\")]}, config=config\n",
    ")\n",
    "\n",
    "for m in output[\"messages\"]:\n",
    "    m.pretty_print()\n",
    "\n",
    "if \"__interrupt__\" in output:\n",
    "    print()\n",
    "    print(\"Interrupt:\")\n",
    "    pprint(output[\"__interrupt__\"][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = agent.invoke(Command(resume={\"action\": \"continue\"}), config=config)\n",
    "\n",
    "for m in output[\"messages\"]:\n",
    "    m.pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent.get_state(config=config)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
