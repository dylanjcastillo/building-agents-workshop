{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nest_asyncio\n",
    "\n",
    "nest_asyncio.apply()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Optional\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "from langchain_core.messages import HumanMessage, SystemMessage\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langsmith import traceable\n",
    "from pydantic import BaseModel\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vanilla workflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class State(BaseModel):\n",
    "    topic: str\n",
    "    table_of_contents: Optional[str] = None\n",
    "    content: Optional[str] = None\n",
    "    revised_content: Optional[str] = None\n",
    "\n",
    "\n",
    "model = ChatOpenAI(model=\"gpt-4.1-mini\")\n",
    "\n",
    "\n",
    "def generate_table_of_contents(state: State) -> str:\n",
    "    messages = [\n",
    "        SystemMessage(\n",
    "            content=\"You are an expert writer specialized in SEO. Provided with a topic, you will generate the table of contents for a short article.\"\n",
    "        ),\n",
    "        HumanMessage(\n",
    "            content=f\"Generate the table of contents of an article about {state.topic}\"\n",
    "        ),\n",
    "    ]\n",
    "    return model.invoke(messages).content\n",
    "\n",
    "\n",
    "def generate_article_content(state: State) -> str:\n",
    "    messages = [\n",
    "        SystemMessage(\n",
    "            content=\"You are an expert writer specialized in SEO. Provided with a topic and a table of contents, you will generate the content of the article.\"\n",
    "        ),\n",
    "        HumanMessage(\n",
    "            content=f\"Generate the content of an article about {state.topic} with the following table of contents: {state.table_of_contents}\"\n",
    "        ),\n",
    "    ]\n",
    "    return model.invoke(messages).content\n",
    "\n",
    "\n",
    "def revise_article_content(state: State) -> str:\n",
    "    messages = [\n",
    "        SystemMessage(\n",
    "            content=\"You are an expert writer specialized in SEO. Provided with a topic, a table of contents and a content, you will revise the content of the article to make it less than 1000 characters.\"\n",
    "        ),\n",
    "        HumanMessage(\n",
    "            content=f\"Revise the content of an article about {state.topic} with the following table of contents: {state.table_of_contents} and the following content:\\n\\n{state.content}\"\n",
    "        ),\n",
    "    ]\n",
    "    return model.invoke(messages).content\n",
    "\n",
    "\n",
    "@traceable\n",
    "def generate_article(topic: str) -> State:\n",
    "    article = State(topic=topic)\n",
    "    article.table_of_contents = generate_table_of_contents(article)\n",
    "    article.content = generate_article_content(article)\n",
    "    if len(article.content) > 1000:\n",
    "        article.revised_content = revise_article_content(article)\n",
    "    return article\n",
    "\n",
    "\n",
    "article = generate_article(\"Artificial Intelligence\")\n",
    "article"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LangGraph implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image, display\n",
    "from langgraph.graph import END, START, StateGraph\n",
    "from typing_extensions import TypedDict\n",
    "\n",
    "\n",
    "class State(TypedDict):\n",
    "    topic: str\n",
    "    table_of_contents: Optional[str] = None\n",
    "    content: Optional[str] = None\n",
    "    revised_content: Optional[str] = None\n",
    "\n",
    "\n",
    "def generate_table_of_contents_lg(state: State) -> dict:\n",
    "    messages = [\n",
    "        SystemMessage(\n",
    "            content=\"You are an expert writer specialized in SEO. Provided with a topic, you will generate the table of contents for a short article.\"\n",
    "        ),\n",
    "        HumanMessage(\n",
    "            content=f\"Generate the table of contents of an article about {state['topic']}\"\n",
    "        ),\n",
    "    ]\n",
    "    return {\"table_of_contents\": model.invoke(messages).content}\n",
    "\n",
    "\n",
    "def generate_article_content_lg(state: State) -> str:\n",
    "    messages = [\n",
    "        SystemMessage(\n",
    "            content=\"You are an expert writer specialized in SEO. Provided with a topic and a table of contents, you will generate the content of the article.\"\n",
    "        ),\n",
    "        HumanMessage(\n",
    "            content=f\"Generate the content of an article about {state['topic']} with the following table of contents: {state['table_of_contents']}\"\n",
    "        ),\n",
    "    ]\n",
    "    return {\"content\": model.invoke(messages).content}\n",
    "\n",
    "\n",
    "def check_article_content(state: State) -> str:\n",
    "    if len(state[\"content\"]) > 1000:\n",
    "        return \"Fail\"\n",
    "    return \"Pass\"\n",
    "\n",
    "\n",
    "def revise_article_content_lg(state: State) -> str:\n",
    "    messages = [\n",
    "        SystemMessage(\n",
    "            content=\"You are an expert writer specialized in SEO. Provided with a topic, a table of contents and a content, you will revise the content of the article to make it less than 1000 characters.\"\n",
    "        ),\n",
    "        HumanMessage(\n",
    "            content=f\"Revise the content of an article about {state['topic']} with the following table of contents: {state['table_of_contents']} and the following content:\\n\\n{state['content']}\"\n",
    "        ),\n",
    "    ]\n",
    "    return {\"revised_content\": model.invoke(messages).content}\n",
    "\n",
    "\n",
    "workflow = StateGraph(State)\n",
    "\n",
    "workflow.add_node(\"generate_table_of_contents\", generate_table_of_contents_lg)\n",
    "workflow.add_node(\"generate_article_content\", generate_article_content_lg)\n",
    "workflow.add_node(\"revise_article_content\", revise_article_content_lg)\n",
    "\n",
    "workflow.add_edge(START, \"generate_table_of_contents\")\n",
    "workflow.add_edge(\"generate_table_of_contents\", \"generate_article_content\")\n",
    "workflow.add_conditional_edges(\n",
    "    source=\"generate_article_content\",\n",
    "    path=check_article_content,\n",
    "    path_map={\"Fail\": \"revise_article_content\", \"Pass\": END},\n",
    ")\n",
    "workflow.add_edge(\"revise_article_content\", END)\n",
    "\n",
    "chain = workflow.compile()\n",
    "\n",
    "display(Image(chain.get_graph().draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state = chain.invoke({\"topic\": \"Artificial Intelligence\"})\n",
    "\n",
    "print(\"Table of contents:\")\n",
    "print(state[\"table_of_contents\"])\n",
    "print(\"\\n--- --- ---\\n\")\n",
    "if \"content\" in state and state[\"content\"] is not None:\n",
    "    print(\"Article content:\")\n",
    "    print(state[\"content\"])\n",
    "    print(\"\\n--- --- ---\\n\")\n",
    "\n",
    "if \"revised_content\" in state:\n",
    "    print(\"Revised article content:\")\n",
    "    print(state[\"revised_content\"])\n",
    "else:\n",
    "    print(\"Article passed quality gate - no revised content detected!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise\n",
    "Build a workflow to generate jokes"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
