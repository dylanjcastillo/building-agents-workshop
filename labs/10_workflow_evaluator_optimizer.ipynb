{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nest_asyncio\n",
    "\n",
    "nest_asyncio.apply()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Optional\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "from IPython.display import Image, display\n",
    "from langchain_core.messages import HumanMessage, SystemMessage\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langgraph.graph import END, START, StateGraph\n",
    "from langsmith import traceable\n",
    "from pydantic import BaseModel, Field\n",
    "from typing_extensions import TypedDict\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vanilla workflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Evaluation(BaseModel):\n",
    "    explanation: str = Field(\n",
    "        description=\"Explain why the text evaluated matches or not the evaluation criteria\"\n",
    "    )\n",
    "    feedback: str = Field(\n",
    "        description=\"Provide feedback to the writer to improve the text\"\n",
    "    )\n",
    "    is_correct: bool = Field(\n",
    "        description=\"Whether the text evaluated matches or not the evaluation criteria\"\n",
    "    )\n",
    "\n",
    "\n",
    "class State(BaseModel):\n",
    "    topic: str\n",
    "    article: Optional[str] = None\n",
    "    evaluation: Optional[Evaluation] = None\n",
    "\n",
    "\n",
    "model = ChatOpenAI(model=\"gpt-4.1-mini\")\n",
    "\n",
    "\n",
    "@traceable\n",
    "def evaluate_text(state: State) -> Evaluation:\n",
    "    model_with_str_output = model.with_structured_output(Evaluation)\n",
    "    messages = [\n",
    "        SystemMessage(\n",
    "            content=\"You are an expert evaluator. Provided with a text, you will evaluate if it's written in British English and if it's appropriate for a young audience. The text must always use British spelling and grammar. Make sure the text doesn't include any em dash.\"\n",
    "        ),\n",
    "        HumanMessage(content=f\"Evaluate the following text:\\n\\n{state.article}\"),\n",
    "    ]\n",
    "    response = model_with_str_output.invoke(messages)\n",
    "    return response\n",
    "\n",
    "\n",
    "@traceable\n",
    "def fix_text(state: State) -> str:\n",
    "    messages = [\n",
    "        SystemMessage(\n",
    "            content=\"You are an expert writer. Provided with a text, you will fix the text to improve it.\"\n",
    "        ),\n",
    "        HumanMessage(\n",
    "            content=f\"You were tasked with writing an article about {state.topic}. You wrote the following text:\\n\\n{state.article}\\n\\nYou've got the following feedback:\\n\\n{state.evaluation.feedback}\\n\\nFix the text to improve it.\"\n",
    "        ),\n",
    "    ]\n",
    "    response = model.invoke(messages)\n",
    "    return response.content\n",
    "\n",
    "\n",
    "@traceable\n",
    "def generate_text(state: State) -> str:\n",
    "    messages = [\n",
    "        SystemMessage(\n",
    "            content=\"You are an expert writer. Provided with a topic, you will generate an engaging article with less than 500 words.\"\n",
    "        ),\n",
    "        HumanMessage(content=f\"Generate a text about this topic:\\n\\n{state.topic}\"),\n",
    "    ]\n",
    "    response = model.invoke(messages)\n",
    "    return response.content\n",
    "\n",
    "\n",
    "@traceable\n",
    "def generate_text_dispatch(state: State) -> str:\n",
    "    if state.evaluation:\n",
    "        return fix_text(state)\n",
    "    return generate_text(state)\n",
    "\n",
    "\n",
    "@traceable\n",
    "def run_workflow(topic: str) -> State:\n",
    "    state = State(topic=topic)\n",
    "\n",
    "    for _ in range(4):\n",
    "        state.article = generate_text_dispatch(state)\n",
    "        state.evaluation = evaluate_text(state)\n",
    "        if state.evaluation.is_correct:\n",
    "            return state\n",
    "\n",
    "    return state\n",
    "\n",
    "\n",
    "state = run_workflow(\"Substance abuse of athletes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LangGraph implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Evaluation(BaseModel):\n",
    "    explanation: str\n",
    "    feedback: str\n",
    "    is_correct: bool\n",
    "\n",
    "\n",
    "class State(TypedDict):\n",
    "    topic: str\n",
    "    article: str\n",
    "    evaluation: Evaluation\n",
    "    num_reviews: int\n",
    "\n",
    "\n",
    "model = ChatOpenAI(model=\"gpt-4.1-mini\", temperature=1)\n",
    "model_evaluator = ChatOpenAI(model=\"gpt-4.1-mini\", temperature=0)\n",
    "\n",
    "\n",
    "def generate_article(state: State) -> dict:\n",
    "    messages = [\n",
    "        SystemMessage(\n",
    "            content=\"You are an expert writer. Provided with a topic, you will generate an engaging article with less than 500 words.\"\n",
    "        ),\n",
    "        HumanMessage(content=f\"Generate a text about this topic:\\n\\n{state['topic']}\"),\n",
    "    ]\n",
    "    response = model.invoke(messages)\n",
    "    return {\"article\": response.content}\n",
    "\n",
    "\n",
    "def fix_article(state: State) -> dict:\n",
    "    messages = [\n",
    "        SystemMessage(\n",
    "            content=\"You are an expert writer. Provided with a text, you will fix the text to improve it. The text must always use British spelling and grammar.\"\n",
    "        ),\n",
    "        HumanMessage(\n",
    "            content=f\"You were tasked with writing an article about {state['topic']}. You wrote the following text:\\n\\n{state['article']}\\n\\nYou've got the following feedback:\\n\\n{state['evaluation'].feedback}\\n\\nFix the text to improve it.\"\n",
    "        ),\n",
    "    ]\n",
    "    response = model.invoke(messages)\n",
    "    return {\"article\": response.content}\n",
    "\n",
    "\n",
    "def evaluate_article(state: State) -> dict:\n",
    "    model_with_str_output = model_evaluator.with_structured_output(Evaluation)\n",
    "    messages = [\n",
    "        SystemMessage(\n",
    "            content=\"You are an expert evaluator. Provided with a text, you will evaluate if it's written in British English and if it's appropriate for a young audience. The text must always use British spelling and grammar. Make sure the text doesn't include any em dash. Be very strict with the evaluation. In case of doubt, return a negative evaluation.\"\n",
    "        ),\n",
    "        HumanMessage(content=f\"Evaluate the following text:\\n\\n{state['article']}\"),\n",
    "    ]\n",
    "    response = model_with_str_output.invoke(messages)\n",
    "    return {\"evaluation\": response, \"num_reviews\": state.get(\"num_reviews\", 0) + 1}\n",
    "\n",
    "\n",
    "def route_text(state: State) -> str:\n",
    "    evaluation = state.get(\"evaluation\", None)\n",
    "    num_reviews = state.get(\"num_reviews\", 0)\n",
    "    if evaluation and not evaluation.is_correct and num_reviews < 3:\n",
    "        return \"Fail\"\n",
    "    return \"Pass\"\n",
    "\n",
    "\n",
    "def generate_article_dispatch(state: State) -> dict:\n",
    "    if \"evaluation\" in state and state[\"evaluation\"]:\n",
    "        return fix_article(state)\n",
    "    else:\n",
    "        return generate_article(state)\n",
    "\n",
    "\n",
    "workflow = StateGraph(State)\n",
    "\n",
    "workflow.add_node(\"generate_article\", generate_article_dispatch)\n",
    "workflow.add_node(\"evaluate_article\", evaluate_article)\n",
    "\n",
    "workflow.add_edge(START, \"generate_article\")\n",
    "workflow.add_edge(\"generate_article\", \"evaluate_article\")\n",
    "workflow.add_conditional_edges(\n",
    "    \"evaluate_article\", route_text, {\"Pass\": END, \"Fail\": \"generate_article\"}\n",
    ")\n",
    "\n",
    "chain = workflow.compile()\n",
    "\n",
    "display(Image(chain.get_graph().draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state = chain.invoke({\"topic\": \"Artificial Intelligence\"})\n",
    "\n",
    "print(\"Article:\")\n",
    "print(state[\"article\"])\n",
    "print(\"\\n--- --- ---\\n\")\n",
    "\n",
    "if \"evaluation\" in state and state[\"evaluation\"] is not None:\n",
    "    print(\"Evaluation:\")\n",
    "    print(state[\"evaluation\"])\n",
    "    print(\"\\n--- --- ---\\n\")\n",
    "\n",
    "    if \"article\" in state:\n",
    "        print(\"Article:\")\n",
    "        print(state[\"article\"])\n",
    "else:\n",
    "    print(\"Article passed quality gate - no revised content detected!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise:\n",
    "\n",
    "Transform the prompt chain workflow that generates recipes into a evaluator optimizer workflow. It should make sure that the recipe is accurate, easy to follow, and that it has few ingredients."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
