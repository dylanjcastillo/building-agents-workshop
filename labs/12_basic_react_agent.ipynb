{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nest_asyncio\n",
    "\n",
    "nest_asyncio.apply()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Literal\n",
    "\n",
    "import requests\n",
    "from dotenv import load_dotenv\n",
    "from IPython.display import Image, display\n",
    "from langchain_core.messages import HumanMessage, SystemMessage, ToolMessage\n",
    "from langchain_core.tools import tool\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langgraph.graph import END, START, MessagesState, StateGraph\n",
    "from langgraph.prebuilt import create_react_agent\n",
    "from langsmith import traceable\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vanilla implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ChatOpenAI(model=\"gpt-4.1-mini\", temperature=0)\n",
    "\n",
    "\n",
    "# THIS IS DANGEROUS, DO NOT USE IN PRODUCTION\n",
    "@tool\n",
    "def run_python_code(code: str) -> str:\n",
    "    \"\"\"Run arbitrary Python code including imports, assignments, and statements. Do not use any external libraries. Save your results as a variable.\n",
    "\n",
    "    Args:\n",
    "        code: Python code to run\n",
    "    \"\"\"\n",
    "    import sys\n",
    "    from io import StringIO\n",
    "\n",
    "    old_stdout = sys.stdout\n",
    "    sys.stdout = captured_output = StringIO()\n",
    "\n",
    "    namespace = {}\n",
    "\n",
    "    try:\n",
    "        exec(code, namespace)\n",
    "\n",
    "        output = captured_output.getvalue()\n",
    "\n",
    "        if not output.strip():\n",
    "            user_vars = {\n",
    "                k: v\n",
    "                for k, v in namespace.items()\n",
    "                if not k.startswith(\"__\") and k not in [\"StringIO\", \"sys\"]\n",
    "            }\n",
    "            if user_vars:\n",
    "                if len(user_vars) == 1:\n",
    "                    output = str(list(user_vars.values())[0])\n",
    "                else:\n",
    "                    output = str(user_vars)\n",
    "\n",
    "        return output.strip() if output.strip() else \"Code executed successfully\"\n",
    "\n",
    "    except Exception as e:\n",
    "        return f\"Error: {str(e)}\"\n",
    "    finally:\n",
    "        sys.stdout = old_stdout\n",
    "\n",
    "\n",
    "# THIS IS DANGEROUS, DO NOT USE IN PRODUCTION\n",
    "\n",
    "tools = [run_python_code]\n",
    "tools_mapping = {tool.name: tool for tool in tools}\n",
    "model_with_tools = model.bind_tools(tools)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@traceable\n",
    "def get_response(question: str):\n",
    "    messages = [\n",
    "        SystemMessage(\n",
    "            \"You're a helpful assistant. Use the tools provided when relevant.\"\n",
    "        ),\n",
    "        HumanMessage(question),\n",
    "    ]\n",
    "    ai_message = model_with_tools.invoke(messages)\n",
    "    messages.append(ai_message)\n",
    "\n",
    "    while ai_message.tool_calls:\n",
    "        for tool_call in ai_message.tool_calls:\n",
    "            selected_tool = tools_mapping[tool_call[\"name\"]]\n",
    "            tool_msg = selected_tool.invoke(tool_call)\n",
    "            messages.append(tool_msg)\n",
    "        ai_message = model_with_tools.invoke(messages)\n",
    "        messages.append(ai_message)\n",
    "\n",
    "    return ai_message.content\n",
    "\n",
    "\n",
    "get_response(\n",
    "    \"Generate 10 random numbers normally distributed with mean 0 and standard deviation 10\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LangGraph implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ChatOpenAI(model=\"gpt-4.1-mini\", temperature=0)\n",
    "\n",
    "\n",
    "# THIS IS DANGEROUS, DO NOT USE IN PRODUCTION\n",
    "@tool\n",
    "def run_python_code(code: str) -> str:\n",
    "    \"\"\"Run arbitrary Python code including imports, assignments, and statements. Do not use any external libraries. Save your results as a variable.\n",
    "\n",
    "    Args:\n",
    "        code: Python code to run\n",
    "    \"\"\"\n",
    "    import sys\n",
    "    from io import StringIO\n",
    "\n",
    "    old_stdout = sys.stdout\n",
    "    sys.stdout = captured_output = StringIO()\n",
    "\n",
    "    namespace = {}\n",
    "\n",
    "    try:\n",
    "        exec(code, namespace)\n",
    "\n",
    "        output = captured_output.getvalue()\n",
    "\n",
    "        if not output.strip():\n",
    "            user_vars = {\n",
    "                k: v\n",
    "                for k, v in namespace.items()\n",
    "                if not k.startswith(\"__\") and k not in [\"StringIO\", \"sys\"]\n",
    "            }\n",
    "            if user_vars:\n",
    "                if len(user_vars) == 1:\n",
    "                    output = str(list(user_vars.values())[0])\n",
    "                else:\n",
    "                    output = str(user_vars)\n",
    "\n",
    "        return output.strip() if output.strip() else \"Code executed successfully\"\n",
    "\n",
    "    except Exception as e:\n",
    "        return f\"Error: {str(e)}\"\n",
    "    finally:\n",
    "        sys.stdout = old_stdout\n",
    "\n",
    "\n",
    "# THIS IS DANGEROUS, DO NOT USE IN PRODUCTION\n",
    "\n",
    "tools = [run_python_code]\n",
    "tools_by_name = {tool.name: tool for tool in tools}\n",
    "model_with_tools = model.bind_tools(tools)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def llm_call(state: MessagesState):\n",
    "    messages = [\n",
    "        SystemMessage(content=\"You are a helpful assistant that can run python code.\"),\n",
    "    ] + state[\"messages\"]\n",
    "    return {\"messages\": [model_with_tools.invoke(messages)]}\n",
    "\n",
    "\n",
    "def tool_node(state: dict):\n",
    "    result = []\n",
    "    for tool_call in state[\"messages\"][-1].tool_calls:\n",
    "        tool = tools_by_name[tool_call[\"name\"]]\n",
    "        observation = tool.invoke(tool_call[\"args\"])\n",
    "        result.append(ToolMessage(content=observation, tool_call_id=tool_call[\"id\"]))\n",
    "    return {\"messages\": result}\n",
    "\n",
    "\n",
    "def should_continue(state: MessagesState) -> Literal[\"environment\", END]:\n",
    "    messages = state[\"messages\"]\n",
    "    last_message = messages[-1]\n",
    "    if last_message.tool_calls:\n",
    "        return \"Action\"\n",
    "    return END"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent_builder = StateGraph(MessagesState)\n",
    "\n",
    "agent_builder.add_node(\"llm_call\", llm_call)\n",
    "agent_builder.add_node(\"environment\", tool_node)\n",
    "\n",
    "agent_builder.add_edge(START, \"llm_call\")\n",
    "agent_builder.add_conditional_edges(\n",
    "    \"llm_call\",\n",
    "    should_continue,\n",
    "    {\n",
    "        \"Action\": \"environment\",\n",
    "        END: END,\n",
    "    },\n",
    ")\n",
    "agent_builder.add_edge(\"environment\", \"llm_call\")\n",
    "\n",
    "agent = agent_builder.compile()\n",
    "\n",
    "display(Image(agent.get_graph(xray=True).draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = [HumanMessage(content=\"Sample 10 values from a uniform distribution\")]\n",
    "\n",
    "messages = agent.invoke({\"messages\": messages})\n",
    "\n",
    "for m in messages[\"messages\"]:\n",
    "    m.pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise\n",
    "Instead of giving a code runner, give the agent multiple tools. Use create_react_agent to create a new agent."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
