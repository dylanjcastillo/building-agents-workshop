{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from typing import Literal\n",
    "\n",
    "import requests\n",
    "from dotenv import load_dotenv\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "from langchain_core.messages import HumanMessage, SystemMessage\n",
    "from langchain_core.tools import tool\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langsmith import traceable\n",
    "from pydantic import BaseModel, Field\n",
    "from serpapi import GoogleSearch\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Single tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ChatOpenAI(model_name=\"gpt-4.1-mini\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tool\n",
    "def find_weather(latitude: float, longitude: float):\n",
    "    \"\"\"Get the weather of a given latitude and longitude\"\"\"\n",
    "    response = requests.get(\n",
    "        f\"https://api.open-meteo.com/v1/forecast?latitude={latitude}&longitude={longitude}&current=temperature_2m,wind_speed_10m&hourly=temperature_2m,relative_humidity_2m,wind_speed_10m\"\n",
    "    )\n",
    "    data = response.json()\n",
    "    return data[\"current\"][\"temperature_2m\"]\n",
    "\n",
    "\n",
    "tools_mapping = {\n",
    "    \"find_weather\": find_weather,\n",
    "}\n",
    "\n",
    "model_with_tools = model.bind_tools([find_weather])\n",
    "\n",
    "\n",
    "@traceable\n",
    "def get_response(question: str):\n",
    "    messages = [\n",
    "        SystemMessage(\n",
    "            \"You're a helpful assistant. Use the tools provided when relevant.\"\n",
    "        ),\n",
    "        HumanMessage(question),\n",
    "    ]\n",
    "    ai_message = model_with_tools.invoke(messages)\n",
    "    messages.append(ai_message)\n",
    "\n",
    "    for tool_call in ai_message.tool_calls:\n",
    "        selected_tool = tools_mapping[tool_call[\"name\"]]\n",
    "        tool_msg = selected_tool.invoke(tool_call)\n",
    "        messages.append(tool_msg)\n",
    "\n",
    "    ai_message = model_with_tools.invoke(messages)\n",
    "    messages.append(ai_message)\n",
    "\n",
    "    return ai_message.content\n",
    "\n",
    "\n",
    "response = get_response(\"What's the weather in Tokyo?\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multiple tools "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ChatOpenAI(model_name=\"gpt-4.1-mini\")\n",
    "\n",
    "\n",
    "@tool\n",
    "def get_weather(latitude: float, longitude: float):\n",
    "    \"\"\"Get the weather of a given latitude and longitude\"\"\"\n",
    "    response = requests.get(\n",
    "        f\"https://api.open-meteo.com/v1/forecast?latitude={latitude}&longitude={longitude}&current=temperature_2m,wind_speed_10m&hourly=temperature_2m,relative_humidity_2m,wind_speed_10m\"\n",
    "    )\n",
    "    data = response.json()\n",
    "    return data[\"current\"][\"temperature_2m\"]\n",
    "\n",
    "\n",
    "@tool\n",
    "def check_guidelines(drafted_response: str) -> str:\n",
    "    \"\"\"Check if a given response follows the company guidelines\"\"\"\n",
    "    model = ChatOpenAI(model_name=\"gpt-4.1-mini\")\n",
    "    response = model.invoke(\n",
    "        [\n",
    "            SystemMessage(\n",
    "                \"You're a helpful assistant. Your task is to check if a given response follows the company guidelines. The company guidelines are that responses should be written in the style of a haiku. You should reply with 'OK' or 'REQUIRES FIXING' and a short explanation.\"\n",
    "            ),\n",
    "            HumanMessage(f\"Current response: {drafted_response}\"),\n",
    "        ]\n",
    "    )\n",
    "    return response.content\n",
    "\n",
    "\n",
    "tools_mapping = {\n",
    "    \"get_weather\": get_weather,\n",
    "    \"check_guidelines\": check_guidelines,\n",
    "}\n",
    "\n",
    "model_with_tools = model.bind_tools([get_weather, check_guidelines])\n",
    "\n",
    "\n",
    "@traceable\n",
    "def get_response(question: str):\n",
    "    messages = [\n",
    "        SystemMessage(\n",
    "            \"You're a helpful assistant. Use the tools provided when relevant. Then draft a response and check if it follows the company guidelines. Only respond to the user after you've validated and modified the response if needed.\"\n",
    "        ),\n",
    "        HumanMessage(question),\n",
    "    ]\n",
    "    ai_message = model_with_tools.invoke(messages)\n",
    "    messages.append(ai_message)\n",
    "\n",
    "    while ai_message.tool_calls:\n",
    "        for tool_call in ai_message.tool_calls:\n",
    "            selected_tool = tools_mapping[tool_call[\"name\"]]\n",
    "            tool_msg = selected_tool.invoke(tool_call)\n",
    "            messages.append(tool_msg)\n",
    "        ai_message = model_with_tools.invoke(messages)\n",
    "        messages.append(ai_message)\n",
    "\n",
    "    return ai_message.content\n",
    "\n",
    "\n",
    "response = get_response(\"What is the temperature in Madrid?\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Structured outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_first_n_pages(file_path: str, n: int = 5):\n",
    "    loader = PyPDFLoader(file_path)\n",
    "    pages = []\n",
    "    for page in loader.lazy_load():\n",
    "        pages.append(page)\n",
    "    return \"\\n\\n\".join([p.page_content for p in pages[:n]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_first_n_pages(file_path: str, n: int = 5):\n",
    "    loader = PyPDFLoader(file_path)\n",
    "    pages = []\n",
    "    for page in loader.lazy_load():\n",
    "        pages.append(page)\n",
    "    return \"\\n\\n\".join([p.page_content for p in pages[:n]])\n",
    "\n",
    "\n",
    "class DocumentInfo(BaseModel):\n",
    "    category: Literal[\"financial\", \"legal\", \"marketing\", \"pets\", \"other\"]\n",
    "    summary: str\n",
    "\n",
    "\n",
    "model = ChatOpenAI(model=\"gpt-4.1-mini\", temperature=0)\n",
    "\n",
    "\n",
    "def get_document_info(document: str) -> DocumentInfo:\n",
    "    model_with_structure = model.with_structured_output(DocumentInfo)\n",
    "    response = model_with_structure.invoke(document)\n",
    "    return response\n",
    "\n",
    "\n",
    "document = get_first_n_pages(\"assets/bbva.pdf\")\n",
    "document_info = get_document_info(document)\n",
    "print(document_info)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise:\n",
    "\n",
    "Build a function calling workflow that let users get the latest news from a company and groups them according to their topic. \n",
    "\n",
    "You should return a structured output with a list of the group topics and the news articles that belong to each topic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NewsGroup(BaseModel):\n",
    "    topic: str = Field(description=\"The topic of the news articles\")\n",
    "    news_articles: list[str] = Field(\n",
    "        description=\"The news articles that belong to the topic\"\n",
    "    )\n",
    "\n",
    "\n",
    "class NewsGroups(BaseModel):\n",
    "    news_groups: list[NewsGroup] = Field(description=\"The news groups\")\n",
    "\n",
    "\n",
    "@tool\n",
    "def search_news(query: str):\n",
    "    \"\"\"Search for news articles for a given query\n",
    "    Args:\n",
    "        query: The query to search for\n",
    "    \"\"\"\n",
    "    params = {\n",
    "        \"q\": query,\n",
    "        \"hl\": \"en\",\n",
    "        \"google_domain\": \"google.com\",\n",
    "        \"api_key\": os.getenv(\"SERPAPI_API_KEY\"),\n",
    "    }\n",
    "\n",
    "    search = GoogleSearch(params)\n",
    "    results = search.get_dict()\n",
    "    return results\n",
    "\n",
    "\n",
    "@tool\n",
    "def group_news(news_articles: list):\n",
    "    \"\"\"Summarize a list of news articles\"\"\"\n",
    "    response = model.invoke(\n",
    "        [\n",
    "            SystemMessage(\n",
    "                \"You're a helpful assistant. Group news articles according to their topic. You will return a list of topics and the news articles that belong to each topic.\"\n",
    "            ),\n",
    "            HumanMessage(f\"News articles: {news_articles}\"),\n",
    "        ]\n",
    "    )\n",
    "    return response.content\n",
    "\n",
    "\n",
    "tools_mapping = {\n",
    "    \"search_news\": search_news,\n",
    "    \"group_news\": group_news,\n",
    "}\n",
    "\n",
    "model_with_tools = model.bind_tools([search_news, group_news])\n",
    "model_with_structure = model.with_structured_output(NewsGroups)\n",
    "\n",
    "\n",
    "@traceable\n",
    "def get_response(question: str):\n",
    "    messages = [\n",
    "        SystemMessage(\n",
    "            \"You're a helpful assistant. Use the tools provided when relevant.\"\n",
    "        ),\n",
    "        HumanMessage(question),\n",
    "    ]\n",
    "    ai_message = model_with_tools.invoke(messages)\n",
    "    messages.append(ai_message)\n",
    "\n",
    "    while ai_message.tool_calls:\n",
    "        for tool_call in ai_message.tool_calls:\n",
    "            selected_tool = tools_mapping[tool_call[\"name\"]]\n",
    "            tool_msg = selected_tool.invoke(tool_call)\n",
    "            messages.append(tool_msg)\n",
    "        ai_message = model_with_tools.invoke(messages)\n",
    "        messages.append(ai_message)\n",
    "\n",
    "    response = model_with_structure.invoke(messages)\n",
    "    return response.news_groups\n",
    "\n",
    "\n",
    "response = get_response(\"What are the latest news about Apple?\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for r in response:\n",
    "    print(r.topic)\n",
    "    print(r.news_articles)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
