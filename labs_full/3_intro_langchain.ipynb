{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "from langchain_core.messages import HumanMessage, SystemMessage\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langsmith import Client\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ChatOpenAI(model=\"gpt-4.1-mini\", seed=42, temperature=0)\n",
    "\n",
    "messages = [\n",
    "    SystemMessage(\"You're Jose. You're a helpful assistant that replies in haikus.\"),\n",
    "    HumanMessage(\"What is the color of the sky?\"),\n",
    "]\n",
    "\n",
    "response = model.invoke(messages)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prompt templates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prompt files (Using Jinja2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "\n",
    "def load_prompt(prompt_filename, partial_variables=None):\n",
    "    partial_variables = partial_variables or {}\n",
    "    with open(prompt_filename, \"r\") as f:\n",
    "        file_content = f.read()\n",
    "        return PromptTemplate.from_template(\n",
    "            file_content, template_format=\"jinja2\", partial_variables=partial_variables\n",
    "        ).format()\n",
    "\n",
    "\n",
    "questions = [\"What is the color of the sky?\", \"What is the color of the grass?\"]\n",
    "\n",
    "messages = [\n",
    "    SystemMessage(load_prompt(\"assets/system_prompt.jinja2\")),\n",
    "    HumanMessage(\n",
    "        load_prompt(\n",
    "            \"assets/user_prompt.jinja2\",\n",
    "            # IMPORTANT: must sanitize the input to avoid Jinja2 injection\n",
    "            partial_variables={\"questions\": questions},\n",
    "        )\n",
    "    ),\n",
    "]\n",
    "\n",
    "response = model.invoke(messages)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prompt catalog (Using LangSmith)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = Client()\n",
    "prompts = client.pull_prompt(\"workshop_system_prompt\")\n",
    "messages = prompts.format_messages(question=\"What is the color of the sky?\")\n",
    "\n",
    "response = model.invoke(messages)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Streaming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chunks = []\n",
    "for chunk in model.stream(messages):\n",
    "    chunks.append(chunk)\n",
    "    print(chunk.content, end=\"\", flush=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multimodality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import base64\n",
    "\n",
    "\n",
    "def image_to_base64_string(image_path):\n",
    "    with open(image_path, \"rb\") as image_file:\n",
    "        s = base64.b64encode(image_file.read())\n",
    "        return s.decode(\"utf-8\")\n",
    "\n",
    "\n",
    "messages = [\n",
    "    SystemMessage(\n",
    "        \"You're Jose. You're a helpful assistant who always replies in haikus.\"\n",
    "    ),\n",
    "    HumanMessage(\n",
    "        content=[\n",
    "            {\"type\": \"text\", \"text\": \"Describe this image:\"},\n",
    "            {\n",
    "                \"type\": \"image\",\n",
    "                \"source_type\": \"base64\",\n",
    "                \"data\": image_to_base64_string(\"assets/dog_image.png\"),\n",
    "                \"mime_type\": \"image/png\",\n",
    "            },\n",
    "        ],\n",
    "    ),\n",
    "]\n",
    "response = model.invoke(messages)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise\n",
    "\n",
    "Create a new set of prompts in the prompt catalog. In it the user should be able to specify the style of the response in addition to the question."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = Client()\n",
    "prompts = client.pull_prompt(\"workshop_homework\")\n",
    "messages = prompts.format_messages(question=\"What is the color of the sky?\", style=\"formal\")\n",
    "\n",
    "model.invoke(messages)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
