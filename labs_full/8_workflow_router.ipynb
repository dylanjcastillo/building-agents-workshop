{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nest_asyncio\n",
    "\n",
    "nest_asyncio.apply()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Literal, Optional\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "from IPython.display import Image, display\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "from langchain_core.messages import HumanMessage, SystemMessage\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langgraph.graph import END, START, StateGraph\n",
    "from langsmith import traceable\n",
    "from pydantic import BaseModel\n",
    "from typing_extensions import TypedDict\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vanilla workflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class State(BaseModel):\n",
    "    input: str\n",
    "    type: Optional[\n",
    "        Literal[\"write_article\", \"generate_table_of_contents\", \"review_article\"]\n",
    "    ] = None\n",
    "    output: Optional[str] = None\n",
    "\n",
    "\n",
    "class MessageType(BaseModel):\n",
    "    type: Literal[\"write_article\", \"generate_table_of_contents\", \"review_article\"]\n",
    "\n",
    "\n",
    "model = ChatOpenAI(model=\"gpt-4.1-mini\")\n",
    "\n",
    "\n",
    "@traceable\n",
    "def classify_message(state: State) -> State:\n",
    "    model_with_str_output = model.with_structured_output(MessageType)\n",
    "    messages = [\n",
    "        SystemMessage(\n",
    "            content=\"You are a helpful assistant. You will classify the message into one of the following categories: 'write_article', 'generate_table_of_contents', 'review_article'.\"\n",
    "        ),\n",
    "        HumanMessage(content=f\"Classify the message: {state.input}\"),\n",
    "    ]\n",
    "    return model_with_str_output.invoke(messages).type\n",
    "\n",
    "\n",
    "@traceable\n",
    "def write_article(state: State) -> State:\n",
    "    messages = [\n",
    "        SystemMessage(\n",
    "            content=\"You are a writer. You will write an article about the topic provided.\"\n",
    "        ),\n",
    "        HumanMessage(content=f\"Write an article about {state.input}\"),\n",
    "    ]\n",
    "    return model.invoke(messages).content\n",
    "\n",
    "\n",
    "@traceable\n",
    "def generate_table_of_contents(state: State) -> State:\n",
    "    messages = [\n",
    "        SystemMessage(\n",
    "            content=\"You are a writer. You will generate a table of contents for an article about the topic provided.\"\n",
    "        ),\n",
    "        HumanMessage(\n",
    "            content=f\"Generate a table of contents for an article about {state.input}\"\n",
    "        ),\n",
    "    ]\n",
    "    return model.invoke(messages).content\n",
    "\n",
    "\n",
    "@traceable\n",
    "def review_article(state: State) -> State:\n",
    "    messages = [\n",
    "        SystemMessage(\n",
    "            content=\"You are a writer. You will review the article for the topic provided.\"\n",
    "        ),\n",
    "        HumanMessage(content=f\"Review the article for the topic {state.input}\"),\n",
    "    ]\n",
    "    return model.invoke(messages).content\n",
    "\n",
    "\n",
    "@traceable\n",
    "def run_workflow(message: str) -> str:\n",
    "    state = State(input=message)\n",
    "    state.type = classify_message(state)\n",
    "    if state.type == \"write_article\":\n",
    "        return write_article(state)\n",
    "    elif state.type == \"generate_table_of_contents\":\n",
    "        return generate_table_of_contents(state)\n",
    "    elif state.type == \"review_article\":\n",
    "        return review_article(state)\n",
    "    else:\n",
    "        return \"I'm sorry, I don't know how to handle that message.\"\n",
    "\n",
    "\n",
    "print(run_workflow(\"Write an article about the meaning of life\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(run_workflow(\"Make a table of contents for an article about the meaning of life\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LangGraph implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class State(TypedDict):\n",
    "    input: str\n",
    "    type: Literal[\"write_article\", \"generate_table_of_contents\", \"review_article\"]\n",
    "    output: str\n",
    "\n",
    "\n",
    "class MessageType(BaseModel):\n",
    "    type: Literal[\"write_article\", \"generate_table_of_contents\", \"review_article\"]\n",
    "\n",
    "\n",
    "def classify_message(message: str) -> dict:\n",
    "    model_with_str_output = model.with_structured_output(MessageType)\n",
    "    messages = [\n",
    "        SystemMessage(\n",
    "            content=\"You are a writer. You will classify the message into one of the following categories: 'write_article', 'generate_table_of_contents', 'review_article'.\"\n",
    "        ),\n",
    "        HumanMessage(content=f\"Classify the message: {message}\"),\n",
    "    ]\n",
    "    return {\"type\": model_with_str_output.invoke(messages).type}\n",
    "\n",
    "\n",
    "def route_message(state: State) -> State:\n",
    "    if state[\"type\"] == \"write_article\":\n",
    "        return \"generate_article_content\"\n",
    "    elif state[\"type\"] == \"generate_table_of_contents\":\n",
    "        return \"generate_table_of_contents\"\n",
    "    elif state[\"type\"] == \"review_article\":\n",
    "        return \"revise_article_content\"\n",
    "    else:\n",
    "        raise ValueError(f\"Invalid message type: {state['type']}\")\n",
    "\n",
    "\n",
    "def generate_table_of_contents(state: State) -> State:\n",
    "    messages = [\n",
    "        SystemMessage(\n",
    "            content=\"You are an expert writer specialized in SEO. Provided with a topic, you will generate the table of contents for a short article.\"\n",
    "        ),\n",
    "        HumanMessage(\n",
    "            content=f\"Generate the table of contents of an article about {state['input']}\"\n",
    "        ),\n",
    "    ]\n",
    "    return {\"output\": model.invoke(messages).content}\n",
    "\n",
    "\n",
    "def generate_article_content(state: State) -> str:\n",
    "    messages = [\n",
    "        SystemMessage(\n",
    "            content=\"You are an expert writer specialized in SEO. Provided with a topic and a table of contents, you will generate the content of the article.\"\n",
    "        ),\n",
    "        HumanMessage(\n",
    "            content=f\"Generate the content of an article about {state['input']}\"\n",
    "        ),\n",
    "    ]\n",
    "    return {\"output\": model.invoke(messages).content}\n",
    "\n",
    "\n",
    "def revise_article_content(state: State) -> str:\n",
    "    messages = [\n",
    "        SystemMessage(\n",
    "            content=\"You are an expert writer specialized in SEO. Provided with a topic, a table of contents and a content, you will revise the content of the article to make it less than 1000 characters.\"\n",
    "        ),\n",
    "        HumanMessage(\n",
    "            content=f\"Revise the content of the following article:\\n\\n{state['input']}\"\n",
    "        ),\n",
    "    ]\n",
    "    return {\"output\": model.invoke(messages).content}\n",
    "\n",
    "\n",
    "workflow = StateGraph(State)\n",
    "\n",
    "workflow.add_node(\"classify_message\", classify_message)\n",
    "workflow.add_conditional_edges(\n",
    "    \"classify_message\",\n",
    "    route_message,\n",
    "    {\n",
    "        \"generate_article_content\": \"generate_article_content\",\n",
    "        \"generate_table_of_contents\": \"generate_table_of_contents\",\n",
    "        \"revise_article_content\": \"revise_article_content\",\n",
    "    },\n",
    ")\n",
    "\n",
    "workflow.add_node(\"generate_table_of_contents\", generate_table_of_contents)\n",
    "workflow.add_node(\"generate_article_content\", generate_article_content)\n",
    "workflow.add_node(\"revise_article_content\", revise_article_content)\n",
    "\n",
    "workflow.add_edge(START, \"classify_message\")\n",
    "workflow.add_edge(\"generate_table_of_contents\", END)\n",
    "workflow.add_edge(\"generate_article_content\", END)\n",
    "workflow.add_edge(\"revise_article_content\", END)\n",
    "\n",
    "chain = workflow.compile()\n",
    "\n",
    "display(Image(chain.get_graph().draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ARTICLE = \"\"\"\n",
    "LangGraph is a library for building workflows. It helps you build workflows that are easy to understand and maintain.\n",
    "\"\"\"\n",
    "\n",
    "state = chain.invoke({\"input\": \"I wrote this article please improve it:\\n\\n\" + ARTICLE})\n",
    "\n",
    "if \"type\" in state and state[\"type\"] is not None:\n",
    "    print(\"Type:\")\n",
    "    print(state[\"type\"])\n",
    "    print(\"\\n--- --- ---\\n\")\n",
    "\n",
    "if \"output\" in state:\n",
    "    print(\"Output:\")\n",
    "    print(state[\"output\"])\n",
    "else:\n",
    "    print(\"No output detected!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise\n",
    "\n",
    "Implement a LangGraph workflow that takes the content of a PDF file and depending on the type of document, it will process the document in a different way. Mock the processing for now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ChatOpenAI(model=\"gpt-4.1-mini\", temperature=0)\n",
    "\n",
    "\n",
    "class State(TypedDict):\n",
    "    path: str\n",
    "    type: Literal[\"financial\", \"legal\", \"marketing\", \"pets\", \"other\"]\n",
    "    document: str\n",
    "    output: str\n",
    "\n",
    "\n",
    "class DocumentType(BaseModel):\n",
    "    type: Literal[\"financial\", \"legal\", \"marketing\", \"pets\", \"other\"]\n",
    "\n",
    "\n",
    "def get_first_n_pages(file_path: str, n: int = 5):\n",
    "    loader = PyPDFLoader(file_path)\n",
    "    pages = []\n",
    "    for page in loader.lazy_load():\n",
    "        pages.append(page)\n",
    "    return \"\\n\\n\".join([p.page_content for p in pages[:n]])\n",
    "\n",
    "\n",
    "def classify_document(state: State) -> dict:\n",
    "    document = get_first_n_pages(state[\"path\"])\n",
    "    model_with_str_output = model.with_structured_output(DocumentType)\n",
    "    messages = [\n",
    "        SystemMessage(\n",
    "            content=\"You are an expert document classifier. You will classify a document into one of the following categories: 'financial', 'legal', 'marketing', 'pets', 'other'.\"\n",
    "        ),\n",
    "        HumanMessage(content=f\"Classify the document: {document}\"),\n",
    "    ]\n",
    "    return {\"type\": model_with_str_output.invoke(messages).type, \"document\": document}\n",
    "\n",
    "\n",
    "def route_message(state: State) -> State:\n",
    "    if state[\"type\"] == \"financial\":\n",
    "        return \"process_financial_document\"\n",
    "    elif state[\"type\"] == \"legal\":\n",
    "        return \"process_legal_document\"\n",
    "    elif state[\"type\"] == \"marketing\":\n",
    "        return \"process_marketing_document\"\n",
    "    elif state[\"type\"] == \"pets\":\n",
    "        return \"process_pets_document\"\n",
    "    elif state[\"type\"] == \"other\":\n",
    "        return \"process_other_document\"\n",
    "    else:\n",
    "        raise ValueError(f\"Invalid message type: {state['type']}\")\n",
    "\n",
    "\n",
    "def process_financial_document(state: State) -> State:\n",
    "    return {\"output\": \"Financial document processed\"}\n",
    "\n",
    "\n",
    "def process_legal_document(state: State) -> State:\n",
    "    return {\"output\": \"Legal document processed\"}\n",
    "\n",
    "\n",
    "def process_marketing_document(state: State) -> State:\n",
    "    return {\"output\": \"Marketing document processed\"}\n",
    "\n",
    "\n",
    "def process_pets_document(state: State) -> State:\n",
    "    return {\"output\": \"Pets document processed\"}\n",
    "\n",
    "\n",
    "def process_other_document(state: State) -> State:\n",
    "    return {\"output\": \"Other document processed\"}\n",
    "\n",
    "\n",
    "workflow = StateGraph(State)\n",
    "\n",
    "workflow.add_node(\"classify_document\", classify_document)\n",
    "workflow.add_node(\"process_financial_document\", process_financial_document)\n",
    "workflow.add_node(\"process_legal_document\", process_legal_document)\n",
    "workflow.add_node(\"process_marketing_document\", process_marketing_document)\n",
    "workflow.add_node(\"process_pets_document\", process_pets_document)\n",
    "workflow.add_node(\"process_other_document\", process_other_document)\n",
    "\n",
    "workflow.add_conditional_edges(\n",
    "    \"classify_document\",\n",
    "    route_message,\n",
    "    {\n",
    "        \"process_financial_document\": \"process_financial_document\",\n",
    "        \"process_legal_document\": \"process_legal_document\",\n",
    "        \"process_marketing_document\": \"process_marketing_document\",\n",
    "        \"process_pets_document\": \"process_pets_document\",\n",
    "        \"other\": \"process_other_document\",\n",
    "    },\n",
    ")\n",
    "\n",
    "workflow.add_edge(START, \"classify_document\")\n",
    "workflow.add_edge(\"process_financial_document\", END)\n",
    "workflow.add_edge(\"process_legal_document\", END)\n",
    "workflow.add_edge(\"process_marketing_document\", END)\n",
    "workflow.add_edge(\"process_pets_document\", END)\n",
    "workflow.add_edge(\"process_other_document\", END)\n",
    "\n",
    "chain = workflow.compile()\n",
    "\n",
    "display(Image(chain.get_graph().draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state = chain.invoke({\"path\": \"assets/dogs.pdf\"})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
