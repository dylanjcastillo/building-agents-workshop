{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nest_asyncio\n",
    "\n",
    "nest_asyncio.apply()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "import operator\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "from IPython.display import Image, display\n",
    "from langchain_core.messages import HumanMessage, SystemMessage\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langgraph.graph import END, START, StateGraph\n",
    "from langgraph.types import Send\n",
    "from langsmith import traceable\n",
    "from pydantic import BaseModel, Field\n",
    "from typing_extensions import Annotated, Optional, TypedDict\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vanilla workflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Section(BaseModel):\n",
    "    name: str = Field(description=\"The name of the section\")\n",
    "    description: str = Field(description=\"The description of the section\")\n",
    "\n",
    "\n",
    "class CompletedSection(BaseModel):\n",
    "    name: str = Field(description=\"The name of the section\")\n",
    "    content: str = Field(description=\"The content of the section\")\n",
    "\n",
    "\n",
    "class Sections(BaseModel):\n",
    "    sections: list[Section] = Field(description=\"The sections of the article\")\n",
    "\n",
    "\n",
    "class OrchestratorState(BaseModel):\n",
    "    topic: str\n",
    "    sections: Optional[list[Section]] = None\n",
    "    completed_sections: Optional[list[CompletedSection]] = None\n",
    "    final_report: Optional[str] = None\n",
    "\n",
    "\n",
    "model = ChatOpenAI(model=\"gpt-4.1-mini\")\n",
    "\n",
    "\n",
    "@traceable\n",
    "async def plan_sections(state: OrchestratorState):\n",
    "    model_planner = model.with_structured_output(Sections)\n",
    "    messages = [\n",
    "        SystemMessage(\n",
    "            content=\"You are an expert writer specialized in SEO. Provided with a topic, you will generate the sections for a short article.\"\n",
    "        ),\n",
    "        HumanMessage(\n",
    "            content=f\"Generate the sections of an article about {state.topic}\"\n",
    "        ),\n",
    "    ]\n",
    "    response = await model_planner.ainvoke(messages)\n",
    "    return response.sections\n",
    "\n",
    "\n",
    "@traceable\n",
    "async def write_section(section: Section) -> str:\n",
    "    messages = [\n",
    "        SystemMessage(\n",
    "            content=\"You are an expert writer specialized in SEO. Provided with a topic and a table of contents, you will generate the content of the article.\"\n",
    "        ),\n",
    "        HumanMessage(\n",
    "            content=f\"Generate the content of an article about {section.name} with the following description: {section.description}\"\n",
    "        ),\n",
    "    ]\n",
    "    response = await model.ainvoke(messages)\n",
    "    return CompletedSection(name=section.name, content=response.content)\n",
    "\n",
    "\n",
    "@traceable\n",
    "def synthesizer(state: OrchestratorState) -> str:\n",
    "    ordered_sections = state.completed_sections\n",
    "    completed_sections_str = \"\\n\\n\".join(\n",
    "        [section.content for section in ordered_sections]\n",
    "    )\n",
    "    return completed_sections_str\n",
    "\n",
    "\n",
    "@traceable\n",
    "async def run_workflow(topic: str) -> OrchestratorState:\n",
    "    state = OrchestratorState(topic=topic)\n",
    "    state.sections = await plan_sections(state)\n",
    "    tasks = [write_section(section) for section in state.sections]\n",
    "    state.completed_sections = await asyncio.gather(*tasks)\n",
    "    state.final_report = synthesizer(state)\n",
    "    return state\n",
    "\n",
    "\n",
    "state = await run_workflow(\"Substance abuse of athletes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LangGraph implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Section(BaseModel):\n",
    "    name: str = Field(description=\"The name of the section\")\n",
    "    description: str = Field(description=\"The description of the section\")\n",
    "\n",
    "\n",
    "class CompletedSection(BaseModel):\n",
    "    name: str = Field(description=\"The name of the section\")\n",
    "    content: str = Field(description=\"The content of the section\")\n",
    "\n",
    "\n",
    "class Sections(BaseModel):\n",
    "    sections: list[Section] = Field(description=\"The sections of the article\")\n",
    "\n",
    "\n",
    "class OrchestratorState(TypedDict):\n",
    "    topic: str\n",
    "    sections: list[Section]\n",
    "    completed_sections: Annotated[list[CompletedSection], operator.add]\n",
    "    final_report: str\n",
    "\n",
    "\n",
    "class WorkerState(TypedDict):\n",
    "    section: str\n",
    "    completed_sections: Annotated[list[Section], operator.add]\n",
    "\n",
    "\n",
    "model = ChatOpenAI(model=\"gpt-4.1-mini\", temperature=0)\n",
    "\n",
    "\n",
    "def orchestrator(state: OrchestratorState) -> dict:\n",
    "    model_planner = model.with_structured_output(Sections)\n",
    "    messages = [\n",
    "        SystemMessage(\n",
    "            content=\"You are an expert writer specialized in SEO. Provided with a topic, you will generate the sections for a short article.\"\n",
    "        ),\n",
    "        HumanMessage(\n",
    "            content=f\"Generate the sections of an article about {state['topic']}\"\n",
    "        ),\n",
    "    ]\n",
    "    return {\"sections\": model_planner.invoke(messages).sections}\n",
    "\n",
    "\n",
    "def write_section(state: WorkerState) -> str:\n",
    "    messages = [\n",
    "        SystemMessage(\n",
    "            content=\"You are an expert writer specialized in SEO. Provided with a topic and a table of contents, you will generate the content of the article.\"\n",
    "        ),\n",
    "        HumanMessage(\n",
    "            content=f\"Generate the content of an article about {state['section'].name} with the following description: {state['section'].description}\"\n",
    "        ),\n",
    "    ]\n",
    "    section = CompletedSection(\n",
    "        name=state[\"section\"].name, content=model.invoke(messages).content\n",
    "    )\n",
    "    return {\"completed_sections\": [section]}\n",
    "\n",
    "\n",
    "def synthesizer(state: OrchestratorState) -> str:\n",
    "    ordered_sections = state[\"completed_sections\"]\n",
    "    completed_sections_str = \"\\n\\n\".join(\n",
    "        [section.content for section in ordered_sections]\n",
    "    )\n",
    "    return {\"final_report\": completed_sections_str}\n",
    "\n",
    "\n",
    "def assign_workers(state: OrchestratorState) -> dict:\n",
    "    return [\n",
    "        Send(\"write_section\", {\"section\": section}) for section in state[\"sections\"]\n",
    "    ]\n",
    "\n",
    "\n",
    "workflow = StateGraph(OrchestratorState)\n",
    "\n",
    "workflow.add_node(\"orchestrator\", orchestrator)\n",
    "workflow.add_node(\"write_section\", write_section)\n",
    "workflow.add_node(\"synthesizer\", synthesizer)\n",
    "\n",
    "workflow.add_edge(START, \"orchestrator\")\n",
    "workflow.add_conditional_edges(\"orchestrator\", assign_workers, [\"write_section\"])\n",
    "workflow.add_edge(\"write_section\", \"synthesizer\")\n",
    "workflow.add_edge(\"synthesizer\", END)\n",
    "\n",
    "chain = workflow.compile()\n",
    "\n",
    "display(Image(chain.get_graph().draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state = chain.invoke({\"topic\": \"Artificial Intelligence\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for section in state[\"sections\"]:\n",
    "    print(section.name)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
